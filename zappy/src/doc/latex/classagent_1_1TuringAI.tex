\doxysection{agent.\+Turing\+AI Class Reference}
\hypertarget{classagent_1_1TuringAI}{}\label{classagent_1_1TuringAI}\index{agent.TuringAI@{agent.TuringAI}}
\doxysubsubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\Hypertarget{classagent_1_1TuringAI_a62358b8fc06220cb6641324595896fd2}\label{classagent_1_1TuringAI_a62358b8fc06220cb6641324595896fd2} 
{\bfseries \+\_\+\+\_\+init\+\_\+\+\_\+} (self)
\item 
\mbox{\hyperlink{classagent_1_1TuringAI_ae687e1745c021ade601fdb5bdee6df35}{update\+\_\+inventory}} (self, response)
\item 
\mbox{\hyperlink{classagent_1_1TuringAI_a93ba73f0f03ee590f8cb0d81c1560712}{nb\+\_\+item}} (self, looked, item)
\item 
\mbox{\hyperlink{classagent_1_1TuringAI_af1b509c4fcbb8539e4141293ce0a1f33}{get\+\_\+state}} (self, response)
\item 
\mbox{\hyperlink{classagent_1_1TuringAI_ac2ed4f4049e650ab83f94234559786dd}{check\+\_\+level\+\_\+up}} (self, box\+\_\+zero)
\item 
\mbox{\hyperlink{classagent_1_1TuringAI_a82f7c550cbcdd59706a5891b75c07bfc}{remember}} (self, state, action, reward, next\+\_\+state, done)
\item 
\mbox{\hyperlink{classagent_1_1TuringAI_a235d3f0e33ebe4d3dff1f792e58f7e99}{train\+\_\+long\+\_\+memory}} (self)
\item 
\mbox{\hyperlink{classagent_1_1TuringAI_ac4f511c3c8899b90cb28025ec29dfa58}{train\+\_\+short\+\_\+memory}} (self, state, action, reward, next\+\_\+state, done)
\item 
\mbox{\hyperlink{classagent_1_1TuringAI_a0ea3f0a15f376839424a7082e606ac6d}{get\+\_\+action}} (self, state)
\item 
\mbox{\hyperlink{classagent_1_1TuringAI_a11800f43c1854d0431dacc98751d381b}{compute\+\_\+reward}} (self, conn, final\+\_\+move, result, elapsed\+\_\+time, res)
\item 
\mbox{\hyperlink{classagent_1_1TuringAI_a431db30c1d26708fbede26edd7b34a9b}{add\+\_\+item}} (self, response, command)
\item 
\mbox{\hyperlink{classagent_1_1TuringAI_a9fa59e24bef0832f21b6e9799d5bdb0b}{save\+\_\+information}} (self)
\item 
\mbox{\hyperlink{classagent_1_1TuringAI_a9056401908a53b26eb62b9528ba430ae}{launch\+\_\+new\+\_\+instance}} (self)
\item 
\mbox{\hyperlink{classagent_1_1TuringAI_ab3fc44f9218a9ff4094db821333d71af}{can\+\_\+fork}} (self, action, result)
\item 
\mbox{\hyperlink{classagent_1_1TuringAI_a546c3291dd7d0dbf2ce06f471f59a176}{train}} (self, conn)
\end{DoxyCompactItemize}
\doxysubsubsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\Hypertarget{classagent_1_1TuringAI_a6383457f0b6aee27ea93d734f7b6a092}\label{classagent_1_1TuringAI_a6383457f0b6aee27ea93d734f7b6a092} 
{\bfseries broadcast\+\_\+string}
\item 
\Hypertarget{classagent_1_1TuringAI_a03c535790ee33ab75cff1463f9c1e954}\label{classagent_1_1TuringAI_a03c535790ee33ab75cff1463f9c1e954} 
{\bfseries debug}
\item 
\Hypertarget{classagent_1_1TuringAI_a4591c57d70dd4c2bd582619ff67de3ff}\label{classagent_1_1TuringAI_a4591c57d70dd4c2bd582619ff67de3ff} 
{\bfseries port}
\item 
\Hypertarget{classagent_1_1TuringAI_a53d3288c360d9fa970078c1892fa880c}\label{classagent_1_1TuringAI_a53d3288c360d9fa970078c1892fa880c} 
{\bfseries conn}
\item 
\Hypertarget{classagent_1_1TuringAI_a007643f89f212e4a8be10f0e1c960693}\label{classagent_1_1TuringAI_a007643f89f212e4a8be10f0e1c960693} 
{\bfseries team\+\_\+name}
\item 
\Hypertarget{classagent_1_1TuringAI_ac6be537b4634e9419d6057478a582f33}\label{classagent_1_1TuringAI_ac6be537b4634e9419d6057478a582f33} 
{\bfseries host}
\item 
\Hypertarget{classagent_1_1TuringAI_accdac965f8a0bd58539e1d4d3fbe1da8}\label{classagent_1_1TuringAI_accdac965f8a0bd58539e1d4d3fbe1da8} 
{\bfseries command}
\item 
\Hypertarget{classagent_1_1TuringAI_a41073e394006bc834468b7c2aade5cb7}\label{classagent_1_1TuringAI_a41073e394006bc834468b7c2aade5cb7} 
{\bfseries ngames}
\item 
\Hypertarget{classagent_1_1TuringAI_adcaef1751676d583006ab872bea339b7}\label{classagent_1_1TuringAI_adcaef1751676d583006ab872bea339b7} 
{\bfseries epsilon}
\item 
\Hypertarget{classagent_1_1TuringAI_ab88366ebb91932e451005e35d81d3096}\label{classagent_1_1TuringAI_ab88366ebb91932e451005e35d81d3096} 
{\bfseries gamma}
\item 
\Hypertarget{classagent_1_1TuringAI_aae1a59e45192588f6d0053e23d8491d0}\label{classagent_1_1TuringAI_aae1a59e45192588f6d0053e23d8491d0} 
{\bfseries memory}
\item 
\Hypertarget{classagent_1_1TuringAI_aeedbe4a653d785db4959cd7cf998770d}\label{classagent_1_1TuringAI_aeedbe4a653d785db4959cd7cf998770d} 
{\bfseries team\+\_\+number}
\item 
\Hypertarget{classagent_1_1TuringAI_aadac5e681cc67c3d64dbbe8fe0616096}\label{classagent_1_1TuringAI_aadac5e681cc67c3d64dbbe8fe0616096} 
{\bfseries device}
\item 
\Hypertarget{classagent_1_1TuringAI_ac0e20d0a7f784437b437e180900526d9}\label{classagent_1_1TuringAI_ac0e20d0a7f784437b437e180900526d9} 
{\bfseries model}
\item 
\Hypertarget{classagent_1_1TuringAI_a58f27e2ed4aa1e9cea421a39beb4d491}\label{classagent_1_1TuringAI_a58f27e2ed4aa1e9cea421a39beb4d491} 
{\bfseries trainer}
\item 
\Hypertarget{classagent_1_1TuringAI_af2720ad18069b60c19365bb70c809af0}\label{classagent_1_1TuringAI_af2720ad18069b60c19365bb70c809af0} 
{\bfseries level}
\item 
\Hypertarget{classagent_1_1TuringAI_a694b9e327e2837d36c8cb274f66afe36}\label{classagent_1_1TuringAI_a694b9e327e2837d36c8cb274f66afe36} 
{\bfseries attempt}
\item 
\Hypertarget{classagent_1_1TuringAI_ab8be694eb26918bd567bebb0aad3f493}\label{classagent_1_1TuringAI_ab8be694eb26918bd567bebb0aad3f493} 
{\bfseries action}
\item 
\Hypertarget{classagent_1_1TuringAI_a8c377a909f661bfdd77b76e807202c29}\label{classagent_1_1TuringAI_a8c377a909f661bfdd77b76e807202c29} 
{\bfseries inventory}
\item 
\Hypertarget{classagent_1_1TuringAI_abcc7d8d999601d8258d6bb6360a5b9aa}\label{classagent_1_1TuringAI_abcc7d8d999601d8258d6bb6360a5b9aa} 
{\bfseries level\+\_\+requirements}
\item 
\Hypertarget{classagent_1_1TuringAI_a6ccf429d21581b98b333ab651e807388}\label{classagent_1_1TuringAI_a6ccf429d21581b98b333ab651e807388} 
{\bfseries children}
\end{DoxyCompactItemize}


\doxysubsection{Member Function Documentation}
\Hypertarget{classagent_1_1TuringAI_a431db30c1d26708fbede26edd7b34a9b}\label{classagent_1_1TuringAI_a431db30c1d26708fbede26edd7b34a9b} 
\index{agent.TuringAI@{agent.TuringAI}!add\_item@{add\_item}}
\index{add\_item@{add\_item}!agent.TuringAI@{agent.TuringAI}}
\doxysubsubsection{\texorpdfstring{add\_item()}{add\_item()}}
{\footnotesize\ttfamily agent.\+Turing\+AI.\+add\+\_\+item (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{response,  }\item[{}]{command }\end{DoxyParamCaption})}

\begin{DoxyVerb}Adds or removes an item from the agent's inventory based on the response and command.

Args:
    response (str): The response received from the server.
    command (str): The command that was sent to the server.

Returns:
    None\end{DoxyVerb}
 \Hypertarget{classagent_1_1TuringAI_ab3fc44f9218a9ff4094db821333d71af}\label{classagent_1_1TuringAI_ab3fc44f9218a9ff4094db821333d71af} 
\index{agent.TuringAI@{agent.TuringAI}!can\_fork@{can\_fork}}
\index{can\_fork@{can\_fork}!agent.TuringAI@{agent.TuringAI}}
\doxysubsubsection{\texorpdfstring{can\_fork()}{can\_fork()}}
{\footnotesize\ttfamily agent.\+Turing\+AI.\+can\+\_\+fork (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{action,  }\item[{}]{result }\end{DoxyParamCaption})}

\begin{DoxyVerb}Checks if forking is possible based on the action and result.

Args:
    action (str): The action being performed.
    result (str or bytes): The result of the action.

Returns:
    bool: True if forking is possible, False otherwise.
\end{DoxyVerb}
 \Hypertarget{classagent_1_1TuringAI_ac2ed4f4049e650ab83f94234559786dd}\label{classagent_1_1TuringAI_ac2ed4f4049e650ab83f94234559786dd} 
\index{agent.TuringAI@{agent.TuringAI}!check\_level\_up@{check\_level\_up}}
\index{check\_level\_up@{check\_level\_up}!agent.TuringAI@{agent.TuringAI}}
\doxysubsubsection{\texorpdfstring{check\_level\_up()}{check\_level\_up()}}
{\footnotesize\ttfamily agent.\+Turing\+AI.\+check\+\_\+level\+\_\+up (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{box\+\_\+zero }\end{DoxyParamCaption})}

\begin{DoxyVerb}Checks if the agent can level up based on the items in box_zero.

Args:
    box_zero (list): The list of items in the agent's possession.

Returns:
    bool: True if the agent can level up, False otherwise.
\end{DoxyVerb}
 \Hypertarget{classagent_1_1TuringAI_a11800f43c1854d0431dacc98751d381b}\label{classagent_1_1TuringAI_a11800f43c1854d0431dacc98751d381b} 
\index{agent.TuringAI@{agent.TuringAI}!compute\_reward@{compute\_reward}}
\index{compute\_reward@{compute\_reward}!agent.TuringAI@{agent.TuringAI}}
\doxysubsubsection{\texorpdfstring{compute\_reward()}{compute\_reward()}}
{\footnotesize\ttfamily agent.\+Turing\+AI.\+compute\+\_\+reward (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{conn,  }\item[{}]{final\+\_\+move,  }\item[{}]{result,  }\item[{}]{elapsed\+\_\+time,  }\item[{}]{res }\end{DoxyParamCaption})}

\begin{DoxyVerb}Computes the reward based on the final move, result, and elapsed time.

Args:
    conn (connection): The connection object used for communication.
    final_move (str): The final move made by the agent.
    result (str or bytes): The result of the final move.
    elapsed_time (float): The elapsed time for the final move.

Returns:
    int: The computed reward based on the final move and result.
\end{DoxyVerb}
 \Hypertarget{classagent_1_1TuringAI_a0ea3f0a15f376839424a7082e606ac6d}\label{classagent_1_1TuringAI_a0ea3f0a15f376839424a7082e606ac6d} 
\index{agent.TuringAI@{agent.TuringAI}!get\_action@{get\_action}}
\index{get\_action@{get\_action}!agent.TuringAI@{agent.TuringAI}}
\doxysubsubsection{\texorpdfstring{get\_action()}{get\_action()}}
{\footnotesize\ttfamily agent.\+Turing\+AI.\+get\+\_\+action (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{state }\end{DoxyParamCaption})}

\begin{DoxyVerb}Returns the action to be taken based on the given state.

Parameters:
state (list): The current state of the agent.

Returns:
int: The index of the action to be taken.
\end{DoxyVerb}
 \Hypertarget{classagent_1_1TuringAI_af1b509c4fcbb8539e4141293ce0a1f33}\label{classagent_1_1TuringAI_af1b509c4fcbb8539e4141293ce0a1f33} 
\index{agent.TuringAI@{agent.TuringAI}!get\_state@{get\_state}}
\index{get\_state@{get\_state}!agent.TuringAI@{agent.TuringAI}}
\doxysubsubsection{\texorpdfstring{get\_state()}{get\_state()}}
{\footnotesize\ttfamily agent.\+Turing\+AI.\+get\+\_\+state (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{response }\end{DoxyParamCaption})}

\begin{DoxyVerb}Get the state of the agent based on the response received.

Args:
    response (str): The response received from the agent.

Returns:
    numpy.ndarray: The state of the agent as a numpy array.\end{DoxyVerb}
 \Hypertarget{classagent_1_1TuringAI_a9056401908a53b26eb62b9528ba430ae}\label{classagent_1_1TuringAI_a9056401908a53b26eb62b9528ba430ae} 
\index{agent.TuringAI@{agent.TuringAI}!launch\_new\_instance@{launch\_new\_instance}}
\index{launch\_new\_instance@{launch\_new\_instance}!agent.TuringAI@{agent.TuringAI}}
\doxysubsubsection{\texorpdfstring{launch\_new\_instance()}{launch\_new\_instance()}}
{\footnotesize\ttfamily agent.\+Turing\+AI.\+launch\+\_\+new\+\_\+instance (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Launches a new instance based on the current state of the agent.

If the agent's food inventory is less than 10, it launches the `sucide.py` script.
If the agent's level is 2 and the food inventory is greater than or equal to 10, it launches the `evolver.py` script.
Otherwise, it launches the `collector.py` script.

The launched scripts are executed in the background and their output is redirected to separate log files.

Returns:
    None
\end{DoxyVerb}
 \Hypertarget{classagent_1_1TuringAI_a93ba73f0f03ee590f8cb0d81c1560712}\label{classagent_1_1TuringAI_a93ba73f0f03ee590f8cb0d81c1560712} 
\index{agent.TuringAI@{agent.TuringAI}!nb\_item@{nb\_item}}
\index{nb\_item@{nb\_item}!agent.TuringAI@{agent.TuringAI}}
\doxysubsubsection{\texorpdfstring{nb\_item()}{nb\_item()}}
{\footnotesize\ttfamily agent.\+Turing\+AI.\+nb\+\_\+item (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{looked,  }\item[{}]{item }\end{DoxyParamCaption})}

\begin{DoxyVerb}Counts the occurrences of a specific item in a comma-separated string.

Args:
    looked (str): A comma-separated string containing items.
    item (str): The item to count occurrences of.

Returns:
    list: A list containing the count of occurrences of the item in each element of the string.
\end{DoxyVerb}
 \Hypertarget{classagent_1_1TuringAI_a82f7c550cbcdd59706a5891b75c07bfc}\label{classagent_1_1TuringAI_a82f7c550cbcdd59706a5891b75c07bfc} 
\index{agent.TuringAI@{agent.TuringAI}!remember@{remember}}
\index{remember@{remember}!agent.TuringAI@{agent.TuringAI}}
\doxysubsubsection{\texorpdfstring{remember()}{remember()}}
{\footnotesize\ttfamily agent.\+Turing\+AI.\+remember (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{state,  }\item[{}]{action,  }\item[{}]{reward,  }\item[{}]{next\+\_\+state,  }\item[{}]{done }\end{DoxyParamCaption})}

\begin{DoxyVerb}Store the experience tuple (state, action, reward, next_state, done) in the agent's memory.

Parameters:
- state: The current state of the environment.
- action: The action taken by the agent.
- reward: The reward received after taking the action.
- next_state: The resulting state after taking the action.
- done: A flag indicating whether the episode is done or not.
\end{DoxyVerb}
 \Hypertarget{classagent_1_1TuringAI_a9fa59e24bef0832f21b6e9799d5bdb0b}\label{classagent_1_1TuringAI_a9fa59e24bef0832f21b6e9799d5bdb0b} 
\index{agent.TuringAI@{agent.TuringAI}!save\_information@{save\_information}}
\index{save\_information@{save\_information}!agent.TuringAI@{agent.TuringAI}}
\doxysubsubsection{\texorpdfstring{save\_information()}{save\_information()}}
{\footnotesize\ttfamily agent.\+Turing\+AI.\+save\+\_\+information (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Saves the agent's information to a file.

If the agent's level is greater than or equal to 2, the information is saved in a file named
'LEVELUPinformation_{team_name}.txt' inside the 'saved_information' directory. Otherwise, the
information is saved in a file named 'information_{team_name}.txt' inside the 'saved_information'
directory.

The saved information includes the team name, attempt number, number of games played, inventory,
and level.

Returns:
    None
\end{DoxyVerb}
 \Hypertarget{classagent_1_1TuringAI_a546c3291dd7d0dbf2ce06f471f59a176}\label{classagent_1_1TuringAI_a546c3291dd7d0dbf2ce06f471f59a176} 
\index{agent.TuringAI@{agent.TuringAI}!train@{train}}
\index{train@{train}!agent.TuringAI@{agent.TuringAI}}
\doxysubsubsection{\texorpdfstring{train()}{train()}}
{\footnotesize\ttfamily agent.\+Turing\+AI.\+train (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{conn }\end{DoxyParamCaption})}

\begin{DoxyVerb}Trains the agent using the given connection.

Args:
    conn: The connection object used to communicate with the environment.

Returns:
    None
\end{DoxyVerb}
 \Hypertarget{classagent_1_1TuringAI_a235d3f0e33ebe4d3dff1f792e58f7e99}\label{classagent_1_1TuringAI_a235d3f0e33ebe4d3dff1f792e58f7e99} 
\index{agent.TuringAI@{agent.TuringAI}!train\_long\_memory@{train\_long\_memory}}
\index{train\_long\_memory@{train\_long\_memory}!agent.TuringAI@{agent.TuringAI}}
\doxysubsubsection{\texorpdfstring{train\_long\_memory()}{train\_long\_memory()}}
{\footnotesize\ttfamily agent.\+Turing\+AI.\+train\+\_\+long\+\_\+memory (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Trains the agent's long-term memory by sampling experiences from the memory buffer and performing a training step.

If the memory buffer contains more experiences than the batch size, a random sample of size BATCH_SIZE is taken.
Otherwise, the entire memory buffer is used as the sample.

The sampled experiences are then unpacked into separate lists for states, actions, rewards, next states, and dones.
These lists are passed to the trainer's `train_step` method for training.

Returns:
    None
\end{DoxyVerb}
 \Hypertarget{classagent_1_1TuringAI_ac4f511c3c8899b90cb28025ec29dfa58}\label{classagent_1_1TuringAI_ac4f511c3c8899b90cb28025ec29dfa58} 
\index{agent.TuringAI@{agent.TuringAI}!train\_short\_memory@{train\_short\_memory}}
\index{train\_short\_memory@{train\_short\_memory}!agent.TuringAI@{agent.TuringAI}}
\doxysubsubsection{\texorpdfstring{train\_short\_memory()}{train\_short\_memory()}}
{\footnotesize\ttfamily agent.\+Turing\+AI.\+train\+\_\+short\+\_\+memory (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{state,  }\item[{}]{action,  }\item[{}]{reward,  }\item[{}]{next\+\_\+state,  }\item[{}]{done }\end{DoxyParamCaption})}

\begin{DoxyVerb}Trains the agent's short-term memory by performing a single training step.

Args:
    state (object): The current state of the environment.
    action (object): The action taken by the agent.
    reward (float): The reward received for taking the action.
    next_state (object): The next state of the environment after taking the action.
    done (bool): Indicates whether the episode has ended.

Returns:
    None
\end{DoxyVerb}
 \Hypertarget{classagent_1_1TuringAI_ae687e1745c021ade601fdb5bdee6df35}\label{classagent_1_1TuringAI_ae687e1745c021ade601fdb5bdee6df35} 
\index{agent.TuringAI@{agent.TuringAI}!update\_inventory@{update\_inventory}}
\index{update\_inventory@{update\_inventory}!agent.TuringAI@{agent.TuringAI}}
\doxysubsubsection{\texorpdfstring{update\_inventory()}{update\_inventory()}}
{\footnotesize\ttfamily agent.\+Turing\+AI.\+update\+\_\+inventory (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{response }\end{DoxyParamCaption})}

\begin{DoxyVerb}Update the agent's inventory based on the response received.

Args:
    response (str): The response string containing the updated inventory information.

Returns:
    None
\end{DoxyVerb}
 

The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
ia/agent.\+py\end{DoxyCompactItemize}
